# Embedding-in-Diffusion-Models
Repository relative to the article "Image embedding for Denoising Generative Models", joint work with D.Evangelista, S.Marro and F.Merizzi.

# Objective
A diffusion model generate consists of a single network trained to denoise data with a parametric amount of noise; then, new samples are generated by iteratively
denoising pure random noise. In the case of so called "implicit" models (DDIM), the generative process is deterministic, hence it becomes interesting to address the 
embedding tasks, that consists in finding a suitable “noisy” image whose denoising results in the original image. In this way, we obtain a functionality similar to an "encoder" in Variational Autoencoders, or a so called recoder for Generative Adversarial Networks.

In the framework of Denoising Models, the task is in this case made more complicated by the non-injective nature of the generator: for each sample x there exists a cloud of elements z able to generate x; we call this set the embedding of x, denoted as emb(x). The task of the Embedding Network is to choose a canonical element
in emb(x). We did a deep investigation of the typical shape of emb(x), aimed to better understand their structure: do they intersect each other? are they simply connected? maybe convex?

# Approach
For the embedding task, we considered both gradient descent approaches,
as well as the definition and training of specific Embedding Networks. The code for both apporaches in contained in this repository.

Among all the architectures for Embedding Networks tested so far, a Unet obtained the best results. The quality
of the embedding is very good, as it can be appreciated by the following pictures, relative to the CelebA dataset

<p align="center"><img src="mnist_syntactic.png" /><p>

<p align="center"><img src="mnist_syntactic.png" /><p>

# Applications
The availability of an Embedding Network has a lot of interesting applications, largely exemplified in the introduction. In general, it opens a wide range
of fascinating perspectives about the exploration of semantic trajectories in
the latent space, the disentanglement of the different aspects of variations, and
the possibility of data editing
